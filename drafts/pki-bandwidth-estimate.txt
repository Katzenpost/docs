Katzenpost Mix Network Bandwidth Estimation

Version 0

Abstract

   This document describes the relationships between mix parameters and
   bandwidth used, and is intended to be helpful for tuning mixes and
   identifying where scaling limitations may exist.

Table of Contents

  1. Introduction
  2. PKI Bandwidth estimation
     2.1 Descriptor exchange
     2.2 Vote exchange
     2.3 Consensus exchange
  3. Analysis
  4. Anonymity Considerations
  5. Security Considerations
  Appendix A. References

1. Introduction

   The Katzenpost Public Key Infrastructure (PKI) specification document
   details the process by which a PKI document is collectively created
   in a voting process that occurs between a set of "Directory Authorities."
   This system is inspired by the Tor Directory Authority system and is very
   similar.

   This means that our consensus document is distributed routinely, and
   contains at least one new mix key for each mix that will be present in the
   next consensus.

   A multi-signatured "Consensus" document that describes the topology of the
   network, and the cryptographic keys in use is produced on a regular schedule
   as described in the pki specification. There are three distinct steps:

   1. Collect the keys from providers, mixes, etc
   2. Exchange a signed copy of these observations with the other voting authorities
   3. Produce and publish a multi-signature document of the observations.


2. PKI Bandwidth Estimation

// XXX we forgot to count providers here!!
Let n, a, c, denote the number of mixes, authorities and clients.
Let d, s, p denote the size (in bytes) of a MixDescriptor, Signature, and Consensus.

e.g.
p = (n * d) + (a * s)

Let b_c denote the amount of bytes used to distribute the Consensus.

2.1 Descriptor exchange

  Each Mix exchanges a MixDescriptor with each Authority:
  Let b_k denote the bytes used to distribute Mix keys:

  b_k = n * d * a

2.2 Vote exchange

  Each Authority exchanges a Vote with every other Authority:

  // XXX we assume that a Vote is the ordered list of MixDescriptors with a
  // Signature and ignore any optimizations. i.e. we assume the whole descriptor
  // with all keys is published each epoch, and not a differential update.
  // This seems a reasonable assumption for now.

  Let b_v denote the bytes used to distribute a Vote between the Authorities.
  Each Authority sends each other Authority a Vote, so for a Authorities, the
  number of Votes sent each epoch is:

    a * (a - 1) = a^2 - a

  And a Vote consists of (approximately) the MixDescriptors and a signature,
  so the amount of bytes spent voting is given by:

    b_v = (n * d + s) * (a^2 - a)

    b_v = a^2 * d * n + a^2 * s - a * d * n - a * s

2.3 Consensus exchange

  Let b_p denote the bytes used to distribute the final consensus to the
  Mixes and clients.

    b_p = (n * d + s * a) * c

  The total bytes used to fetch, vote, and distribute MixDescriptors is
  then:

    b_c = b_k + b_v + b_p

        = n * d * a  +  (n * d + s) * (a^2 - a)  +  (n * d + s * a) * c

        = a^2 * d * n + a^2 * s + a * c * s - a * s + c * d * n

  Note that this quantity is in units of bytes, for convenience.

  The bandwidth (bits/second) used to distribute the consensus is then:

    8 * b_p / epoch_period

  The average bandwidth each client will use per consensus period is then:

    8 * b_p / (c * epoch_period)

  // XXX clients will need the consensus, so the average bandwidth over
  // the epoch period isn't really a good estimate for peak bandwidth
  // required. (but this is the providers problem, as the consensus will
  // be served to the clients by their provider)
  // We might say that clients should have obtained a valid
  // copy of the consensus by a certain deadline, however.

Analysis

Let k be defined as the ratio of mixes to clients:

// XXX: Add section/notes on anonymity considerations.
// in particular, anonymity ought to increase as anonymity set
// gets bigger, ie somehow inversely proportional to k.

k = n / c
 or
n = c * k

Then, substituting for n:

  b_c = a^2 * c * d * k a^2 * s + a * c * s - a * s + c^2 * d * k

For values of c >> a (i.e. 9 authorities and 10^6 clients)

  b_c ~ a * c * s - a * s + c^2 * d * k

  b_c ~ c^2 * d * k

The dominant term is clearly c^2 * d * k, and scaling is limited by the factor
'k'.  k is just the ratio n / c, which is determined by mix bandwidth
rate and the client bandwidth rate required given the supplied parameters.
// XXX assumes that aside from the consensus process, the network can be scaled
// linearly by just adding more mixes proportionally to users.

If the ratio of consensus distribution bandwidth to network overall bandwidth
is plotted as a function of the number of clients, eventually consensus bandwidth
will consume more bandwidth than the client is using for communication.
consensus bandwidth / (consensus bandwidth + client bandwidth)

// XXX I think someone performed a similar analysis for the Tor consensus
// while evaluating scaling constraints. Link it here.

// XXX Note that client bandwidth usage will likely follow diurnal pattern
// assuming that clients are not online constantly.
// This seems a reasonable assumption.
// XXX Assumes the network will be provisioned with sufficient capacity
// without adding additional mixes during the day.
// I don't know if this is a reasonable assumption.
// Maybe it makes sense to try and keep the number of clients per mix constant
// by taking mixes online/offline. Anonymity analysis? Well obviously this
// could leak the approximate numbers of users of the network, but the
// alternative is that less client traffic is available for mixing with at
// each mix.


// Consider the bandwidth fraction (of total) used to distribute the pki information:

Let kr denote the rate at which the consensus is rotated.
kr = 1 / epoch_period

// XXX use proper parameter names
Let sm denote the size of a message

Let l_p denote the frequency of sending a message (LAMBDA_P)

And cbr denote the client average bandwidth rate (for all clients in the network)

cbr = sm * l_p * c

Let mbr denote the mix average bandwidth rate
Let nbr denote the network average bandwidth rate (for all traffic on the network)

nbr = cbr + kr * b_c

// XXX how do we model mbr accurately?
// XXX - I think I am making a mistake here, and the bandwidth of the network
// is constrained by the topology of the network - ie the network bandwidth
// is limited by the width of the strata - how many mixes / number of strata
// so this should probably be another parameter...
mbr = nbr / n

// substituting c = n / k
nbr = cbr + kr b_c
    = sm * l_p * (n / k) + kr b_c

// XXX: idea is to pick particular values for sm, l_p, and other parameters as
// suggested by the intended application, and then plot dependent variables, solve
// with additional constraints, etc.

// Set up the equation in terms of mix average bandwidth
nbr = n mbr

n mbr = (n/k) cbr
mbr = ((n/k) cbr)n^-1
mbr = cbr/k

// solve for a value of mbr that seems realistic
// XXX: just assumes that mixes can forward at line rate (1Gb/s) and
// we are going to pick a utilization factor of 50% for this estimation.

Let mbr be .5 GB/s

// Now pick a value for cbr :)
// XXX: assumes client has specific bandwidth needs that we want to guarantee
// and that cover traffic will be some multiple of this value.
// XXX: but we need a better understanding of how to model the uncertainty
// provided by cover traffic. Here we're just saying that cover traffic
// is some multiple of a chosen capacity required.
Let bc = bandwidth capacity required for communication

// we know that clients transmit with frequency l_p (seconds)
// so the required bandwidth per client is message_size / l_p
bc = message_size / l_p

// XXX How much cover traffic is needed to provide
// how much uncertainty?
// XXX what ratio of loop to drop cover traffic should be used, and why.
// XXX what is the (bandwidth) cost of a loop vs a drop?
// for now we just use a parameter that is the ratio of cover traffic to messaging traffic.
// nsr = ratio noise / signal
// network client bandwidth  = noise-to-signal * bandwidth per client

cbr = nsr * bc
mbr = cbr / k

solve for k, given mbr and bc
mbr = (nsr * bc) / k
k = (nsr * bc) / mbr

// an example with an assumed mix average bandwidth rate at .5GB
// and bc = 512b/.3s, nsr = 2
k = (2 * 512b/.3) / .5*10^9b
clients per mix = 1 / k

Interesting things to plot ( see python script )
  number of mix nodes required for varying numbers of clients, or message sizes.
  the consensus bandwidth ratio as a function of number of clients


Appendix A.
# XXX fixme.
# at least add a citation to the pki document and the tor consensus scalability research
